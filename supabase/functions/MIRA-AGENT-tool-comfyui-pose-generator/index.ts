import { serve } from "https://deno.land/std@0.190.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.45.0';

const COMFYUI_ENDPOINT_URL = Deno.env.get('COMFYUI_ENDPOINT_URL');
const SUPABASE_URL = Deno.env.get('SUPABASE_URL');
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
const UPLOAD_BUCKET = 'mira-agent-user-uploads';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const workflowWithoutRef = {"6":{"inputs":{"text":["192",0],"clip":["212",1]},"class_type":"CLIPTextEncode","_meta":{"title":"CLIP Text Encode (Positive Prompt)"}},"8":{"inputs":{"samples":["197",0],"vae":["39",0]},"class_type":"VAEDecode","_meta":{"title":"VAE Decode"}},"35":{"inputs":{"guidance":3.5,"conditioning":["177",0]},"class_type":"FluxGuidance","_meta":{"title":"FluxGuidance"}},"37":{"inputs":{"unet_name":"flux1-kontext-dev.safetensors","weight_dtype":"default"},"class_type":"UNETLoader","_meta":{"title":"Load Diffusion Model"}},"38":{"inputs":{"clip_name1":"clip_l.safetensors","clip_name2":"t5xxl_fp16.safetensors","type":"flux","device":"default"},"class_type":"DualCLIPLoader","_meta":{"title":"DualCLIPLoader"}},"39":{"inputs":{"vae_name":"ae.safetensors"},"class_type":"VAELoader","_meta":{"title":"Load VAE"}},"124":{"inputs":{"pixels":["146",0],"vae":["39",0]},"class_type":"VAEEncode","_meta":{"title":"VAE Encode"}},"135":{"inputs":{"conditioning":["6",0]},"class_type":"ConditioningZeroOut","_meta":{"title":"ConditioningZeroOut"}},"146":{"inputs":{"direction":"right","match_image_size":true,"spacing_width":32,"spacing_color":"white","image1":["214",0]},"class_type":"ImageStitch","_meta":{"title":"Image Stitch"}},"177":{"inputs":{"conditioning":["6",0],"latent":["124",0]},"class_type":"ReferenceLatent","_meta":{"title":"ReferenceLatent"}},"190":{"inputs":{"prompt":["193",0],"safety_settings":"BLOCK_NONE","response_type":"text","model":"gemini-2.5-pro","api_key":"AIzaSyByuyPAPHMnftan3cvqaZRTTwlGATYinnA","proxy":"","system_instruction":["195",0],"error_fallback_value":"","seed":959188114,"temperature":0.7500000000000001,"num_predict":0,"image_1":["146",0]},"class_type":"Ask_Gemini","_meta":{"title":"Ask Gemini"}},"192":{"inputs":{"value":["190",0]},"class_type":"PrimitiveString","_meta":{"title":"String"}},"193":{"inputs":{"String":"change their pose to match this : insert pose here, keep everything else the same"},"class_type":"String","_meta":{"title":"editing task"}},"194":{"inputs":{"text_0":"Using the pose from the second reference image, edit the man from the first image. Change his pose to a straight-on stance, facing the camera with his arms down at his sides. Replace his white t-shirt with a vibrant orange jacket. Preserve the man's exact facial features, hairstyle, skin tone, tattoos, and his black cargo pants. Maintain the original background from the first image, including the stone building and arched windows, without any changes to lighting or camera angle.","text":["192",0]},"class_type":"ShowText|pysssss","_meta":{"title":"Show Text üêç"}},"195":{"inputs":{"String":"You are an expert prompt engineer for a powerful image-to-image editing model called \"Kontext\". Your sole purpose is to receive a user's editing request and one or more images, and translate that request into a single, optimized, and highly effective prompt for the Kontext model. The final prompt must be in English and must not exceed 512 tokens.\nYour process is to first apply the General Principles to all requests, and then check if any Special Image Handling rules apply.\nPart 1: General Principles for All Edits\nThese are your foundational rules for constructing any prompt.\nA. Core Mandate: Specificity and Preservation\nBe Specific: Always translate vague user requests (\"make it cool\") into precise instructions (\"increase the color contrast and apply a cinematic lighting effect\").\nPreserve by Default: Your most important task is to identify what should not change. Proactively add clauses to preserve key aspects of the image (e.g., background, pose, lighting). When in doubt, add a preservation instruction.\nIdentify Subjects Clearly: Never use vague pronouns (\"her\", \"it\"). Describe the subject based on the reference image (\"the man in the orange jacket,\" \"the red car on the left\").\nB. Verb Choice is Crucial\nUse controlled verbs like \"Change,\" \"Replace,\" \"Add,\" or \"Remove\" for targeted edits (\"Replace the background with a forest\").\nUse \"Transform\" only for significant, holistic style changes. To avoid unwanted identity changes, prefer \"Change the clothes\" over \"Transform the person.\"\nC. Character and Identity Consistency\nWhen editing a person, preserving their identity is paramount. ALWAYS add a clause to maintain their unique features.\nExample: \"Change the man's clothes to a viking warrior's outfit while preserving his exact facial features, eye color, and facial expression.\"\nD. Composition and Background Control\nWhen a user asks to change the environment, you must ensure the subject's position, scale, and pose are maintained.\nUser Request: \"Put him on a beach.\"\nYour Optimized Prompt: \"Change the background to a sunny beach while keeping the person in the exact same position, scale, and pose. Maintain the identical camera angle, framing, and perspective. Only replace the environment around them.\"\nE. Text Editing: Use a Strict Format\nFormat: Replace '[original text]' with '[new text]'\nInstructions: Use single quotation marks. Infer the '[original text]' from the reference image and pay attention to case sensitivity.\nExample: \"Replace 'joy' with 'FLUX' while maintaining the same font style and color.\"\nF. Style Transfer (via Text)\nNamed Style: If a user names a style, use it directly. \"Make it pop art\" becomes \"Transform to a 1960s pop art poster style.\"\nDescribed Style: If a user describes a style, translate their description. \"Make it look like a sketch\" becomes \"Convert to a pencil sketch with natural graphite lines and visible paper texture.\"\nPart 2: Special Image Handling Rules\nAfter considering the general principles, check if one of these specific input formats applies.\nCase 1: The Input is a Composite/Stitched Image\nThis is a high-priority rule. If you are given a single image that is clearly composed of two separate images stitched together side-by-side, you must follow this logic:\nIdentify Roles by Position: The image on the left is the primary content image (the subject to be edited). The image on the right is the style/object reference.\nFormulate a Self-Contained, Descriptive Prompt: Your prompt must not simply point to the reference (e.g., 'like the image on the right'). Instead, you must verbally describe the key attributes from the reference image and apply them to the content image. The resulting prompt should be so descriptive that it is almost understandable without seeing the reference part of the image.\nExample Scenario:\nInput Image: A single wide image showing a man in an orange bomber jacket (left), and a person in a red-and-white striped shirt (right).\nUser Request: \"Change his jacket to have the pattern of that shirt.\"\nYour Optimized Prompt: \"For the man in the orange jacket, replace his jacket with a short-sleeved, collared shirt featuring a pattern of thin, horizontal red and white stripes. Preserve the man's exact facial features, pose, sunglasses, and the original background.\"\nCase 2: The Input is Multiple, Separate Image Files\nIf the user provides more than one separate image file:\nIdentify Roles: The first image is the primary content reference, and the second (and any subsequent) image is a style reference.\nStructure Prompt: Begin with \"Using the style from the provided reference image, ...\" followed by the editing instruction.\nExample: User provides a photo of their dog (Image 1) and a watercolor painting (Image 2). Request: \"make my dog photo look like this painting.\"\nYour Optimized Prompt: \"Using the style from the provided painting, transform the photo of the dog into a watercolor painting, while preserving the dog's pose and features.\"\nSummary of Your Task:\nYour output is NOT a conversation; it is ONLY the final, optimized prompt. Analyze the user's request and the provided image(s). First, determine the image format (single, composite, or multiple). Then, apply the relevant principles to construct a single, precise, and explicit instruction. When in doubt, add more detail to preserve the elements that are not being changed."},"class_type":"String","_meta":{"title":"roleprompt for editing task"}},"196":{"inputs":{"cfg":1,"nag_scale":7.5,"nag_tau":2.5,"nag_alpha":0.25,"nag_sigma_end":0,"model":["212",0],"positive":["35",0],"negative":["135",0],"nag_negative":["198",0],"latent_image":["124",0]},"class_type":"NAGCFGGuider","_meta":{"title":"NAGCFGGuider"}},"197":{"inputs":{"noise":["200",0],"guider":["196",0],"sampler":["202",0],"sigmas":["204",0],"latent_image":["124",0]},"class_type":"SamplerCustomAdvanced","_meta":{"title":"SamplerCustomAdvanced"}},"198":{"inputs":{"conditioning":["6",0]},"class_type":"ConditioningZeroOut","_meta":{"title":"ConditioningZeroOut"}},"200":{"inputs":{"noise_seed":558971480754733},"class_type":"RandomNoise","_meta":{"title":"RandomNoise"}},"202":{"inputs":{"sampler_name":"euler"},"class_type":"KSamplerSelect","_meta":{"title":"KSamplerSelect"}},"204":{"inputs":{"scheduler":"simple","steps":20,"denoise":1,"model":["37",0]},"class_type":"BasicScheduler","_meta":{"title":"BasicScheduler"}},"212":{"inputs":{"lora_name":"42lux-UltimateAtHome-flux-highresfix%20(1).safetensors","strength_model":0.5000000000000001,"strength_clip":0.5000000000000001,"model":["37",0],"clip":["38",0]},"class_type":"LoraLoader","_meta":{"title":"Load LoRA"}},"213":{"inputs":{"filename_prefix":"ComfyUI","images":["8",0]},"class_type":"SaveImage","_meta":{"title":"Output_BackUP-version"}},"214":{"inputs":{"image":"10001.jpg"},"class_type":"LoadImage","_meta":{"title":"Original_Image"}}};
const workflowWithRef = {"6":{"inputs":{"text":["192",0],"clip":["212",1]},"class_type":"CLIPTextEncode","_meta":{"title":"CLIP Text Encode (Positive Prompt)"}},"8":{"inputs":{"samples":["197",0],"vae":["39",0]},"class_type":"VAEDecode","_meta":{"title":"VAE Decode"}},"35":{"inputs":{"guidance":3.5,"conditioning":["177",0]},"class_type":"FluxGuidance","_meta":{"title":"FluxGuidance"}},"37":{"inputs":{"unet_name":"flux1-kontext-dev.safetensors","weight_dtype":"default"},"class_type":"UNETLoader","_meta":{"title":"Load Diffusion Model"}},"38":{"inputs":{"clip_name1":"clip_l.safetensors","clip_name2":"t5xxl_fp16.safetensors","type":"flux","device":"default"},"class_type":"DualCLIPLoader","_meta":{"title":"DualCLIPLoader"}},"39":{"inputs":{"vae_name":"ae.safetensors"},"class_type":"VAELoader","_meta":{"title":"Load VAE"}},"124":{"inputs":{"pixels":["146",0],"vae":["39",0]},"class_type":"VAEEncode","_meta":{"title":"VAE Encode"}},"135":{"inputs":{"conditioning":["6",0]},"class_type":"ConditioningZeroOut","_meta":{"title":"ConditioningZeroOut"}},"146":{"inputs":{"direction":"right","match_image_size":true,"spacing_width":32,"spacing_color":"white","image1":["214",0]},"class_type":"ImageStitch","_meta":{"title":"Image Stitch"}},"177":{"inputs":{"conditioning":["6",0],"latent":["124",0]},"class_type":"ReferenceLatent","_meta":{"title":"ReferenceLatent"}},"190":{"inputs":{"prompt":["193",0],"safety_settings":"BLOCK_NONE","response_type":"text","model":"gemini-2.5-pro","api_key":"AIzaSyByuyPAPHMnftan3cvqaZRTTwlGATYinnA","proxy":"","system_instruction":["195",0],"error_fallback_value":"","seed":959188114,"temperature":0.7500000000000001,"num_predict":0,"image_1":["146",0],"image_2":["215",0]},"class_type":"Ask_Gemini","_meta":{"title":"Ask Gemini"}},"192":{"inputs":{"value":["190",0]},"class_type":"PrimitiveString","_meta":{"title":"String"}},"193":{"inputs":{"String":"change their pose to match my reference, keep everything else the same"},"class_type":"String","_meta":{"title":"editing task"}},"194":{"inputs":{"text_0":"Using the pose from the second reference image, edit the man from the first image. Change his pose to a straight-on stance, facing the camera with his arms down at his sides. Replace his white t-shirt with a vibrant orange jacket. Preserve the man's exact facial features, hairstyle, skin tone, tattoos, and his black cargo pants. Maintain the original background from the first image, including the stone building and arched windows, without any changes to lighting or camera angle.","text":["192",0]},"class_type":"ShowText|pysssss","_meta":{"title":"Show Text üêç"}},"195":{"inputs":{"String":"You are an expert prompt engineer for a powerful image-to-image editing model called \"Kontext\". Your sole purpose is to receive a user's editing request and one or more images, and translate that request into a single, optimized, and highly effective prompt for the Kontext model. The final prompt must be in English and must not exceed 512 tokens.\nYour process is to first apply the General Principles to all requests, and then check if any Special Image Handling rules apply.\nPart 1: General Principles for All Edits\nThese are your foundational rules for constructing any prompt.\nA. Core Mandate: Specificity and Preservation\nBe Specific: Always translate vague user requests (\"make it cool\") into precise instructions (\"increase the color contrast and apply a cinematic lighting effect\").\nPreserve by Default: Your most important task is to identify what should not change. Proactively add clauses to preserve key aspects of the image (e.g., background, pose, lighting). When in doubt, add a preservation instruction.\nIdentify Subjects Clearly: Never use vague pronouns (\"her\", \"it\"). Describe the subject based on the reference image (\"the man in the orange jacket,\" \"the red car on the left\").\nB. Verb Choice is Crucial\nUse controlled verbs like \"Change,\" \"Replace,\" \"Add,\" or \"Remove\" for targeted edits (\"Replace the background with a forest\").\nUse \"Transform\" only for significant, holistic style changes. To avoid unwanted identity changes, prefer \"Change the clothes\" over \"Transform the person.\"\nC. Character and Identity Consistency\nWhen editing a person, preserving their identity is paramount. ALWAYS add a clause to maintain their unique features.\nExample: \"Change the man's clothes to a viking warrior's outfit while preserving his exact facial features, eye color, and facial expression.\"\nD. Composition and Background Control\nWhen a user asks to change the environment, you must ensure the subject's position, scale, and pose are maintained.\nUser Request: \"Put him on a beach.\"\nYour Optimized Prompt: \"Change the background to a sunny beach while keeping the person in the exact same position, scale, and pose. Maintain the identical camera angle, framing, and perspective. Only replace the environment around them.\"\nE. Text Editing: Use a Strict Format\nFormat: Replace '[original text]' with '[new text]'\nInstructions: Use single quotation marks. Infer the '[original text]' from the reference image and pay attention to case sensitivity.\nExample: \"Replace 'joy' with 'FLUX' while maintaining the same font style and color.\"\nF. Style Transfer (via Text)\nNamed Style: If a user names a style, use it directly. \"Make it pop art\" becomes \"Transform to a 1960s pop art poster style.\"\nDescribed Style: If a user describes a style, translate their description. \"Make it look like a sketch\" becomes \"Convert to a pencil sketch with natural graphite lines and visible paper texture.\"\nPart 2: Special Image Handling Rules\nAfter considering the general principles, check if one of these specific input formats applies.\nCase 1: The Input is a Composite/Stitched Image\nThis is a high-priority rule. If you are given a single image that is clearly composed of two separate images stitched together side-by-side, you must follow this logic:\nIdentify Roles by Position: The image on the left is the primary content image (the subject to be edited). The image on the right is the style/object reference.\nFormulate a Self-Contained, Descriptive Prompt: Your prompt must not simply point to the reference (e.g., 'like the image on the right'). Instead, you must verbally describe the key attributes from the reference image and apply them to the content image. The resulting prompt should be so descriptive that it is almost understandable without seeing the reference part of the image.\nExample Scenario:\nInput Image: A single wide image showing a man in an orange bomber jacket (left), and a person in a red-and-white striped shirt (right).\nUser Request: \"Change his jacket to have the pattern of that shirt.\"\nYour Optimized Prompt: \"For the man in the orange jacket, replace his jacket with a short-sleeved, collared shirt featuring a pattern of thin, horizontal red and white stripes. Preserve the man's exact facial features, pose, sunglasses, and the original background.\"\nCase 2: The Input is Multiple, Separate Image Files\nIf the user provides more than one separate image file:\nIdentify Roles: The first image is the primary content reference, and the second (and any subsequent) image is a style reference.\nStructure Prompt: Begin with \"Using the style from the provided reference image, ...\" followed by the editing instruction.\nExample: User provides a photo of their dog (Image 1) and a watercolor painting (Image 2). Request: \"make my dog photo look like this painting.\"\nYour Optimized Prompt: \"Using the style from the provided painting, transform the photo of the dog into a watercolor painting, while preserving the dog's pose and features.\"\nSummary of Your Task:\nYour output is NOT a conversation; it is ONLY the final, optimized prompt. Analyze the user's request and the provided image(s). First, determine the image format (single, composite, or multiple). Then, apply the relevant principles to construct a single, precise, and explicit instruction. When in doubt, add more detail to preserve the elements that are not being changed."},"class_type":"String","_meta":{"title":"roleprompt for editing task"}},"196":{"inputs":{"cfg":1,"nag_scale":7.5,"nag_tau":2.5,"nag_alpha":0.25,"nag_sigma_end":0,"model":["212",0],"positive":["35",0],"negative":["135",0],"nag_negative":["198",0],"latent_image":["124",0]},"class_type":"NAGCFGGuider","_meta":{"title":"NAGCFGGuider"}},"197":{"inputs":{"noise":["200",0],"guider":["196",0],"sampler":["202",0],"sigmas":["204",0],"latent_image":["124",0]},"class_type":"SamplerCustomAdvanced","_meta":{"title":"SamplerCustomAdvanced"}},"198":{"inputs":{"conditioning":["6",0]},"class_type":"ConditioningZeroOut","_meta":{"title":"ConditioningZeroOut"}},"200":{"inputs":{"noise_seed":558971480754733},"class_type":"RandomNoise","_meta":{"title":"RandomNoise"}},"202":{"inputs":{"sampler_name":"euler"},"class_type":"KSamplerSelect","_meta":{"title":"KSamplerSelect"}},"204":{"inputs":{"scheduler":"simple","steps":20,"denoise":1,"model":["37",0]},"class_type":"BasicScheduler","_meta":{"title":"BasicScheduler"}},"212":{"inputs":{"lora_name":"42lux-UltimateAtHome-flux-highresfix%20(1).safetensors","strength_model":0.5000000000000001,"strength_clip":0.5000000000000001,"model":["37",0],"clip":["38",0]},"class_type":"LoraLoader","_meta":{"title":"Load LoRA"}},"213":{"inputs":{"filename_prefix":"ComfyUI","images":["8",0]},"class_type":"SaveImage","_meta":{"title":"Output_BackUP-version"}},"214":{"inputs":{"image":"10001.jpg"},"class_type":"LoadImage","_meta":{"title":"Original_Image"}},"215":{"inputs":{"image":"10001.jpg"},"class_type":"LoadImage","_meta":{"title":"Pose_image"}}};

async function downloadFromSupabase(supabase: any, publicUrl: string): Promise<Blob> {
    const url = new URL(publicUrl);
    const pathSegments = url.pathname.split('/');
    const bucketName = pathSegments[pathSegments.indexOf('public') + 1];
    const filePath = pathSegments.slice(pathSegments.indexOf(bucketName) + 1).join('/');
    const { data, error } = await supabase.storage.from(bucketName).download(filePath);
    if (error) throw new Error(`Supabase download failed: ${error.message}`);
    return data;
}

async function uploadToComfyUI(comfyUiUrl: string, imageBlob: Blob, filename: string) {
  const formData = new FormData();
  formData.append('image', imageBlob, filename);
  formData.append('overwrite', 'true');
  const uploadUrl = `${comfyUiUrl}/upload/image`;
  const response = await fetch(uploadUrl, { method: 'POST', body: formData });
  if (!response.ok) throw new Error(`ComfyUI upload failed: ${await response.text()}`);
  const data = await response.json();
  return data.name;
}

serve(async (req) => {
  const requestId = `pose-generator-${Date.now()}`;
  if (req.method === 'OPTIONS') { return new Response(null, { headers: corsHeaders }); }
  if (!COMFYUI_ENDPOINT_URL) throw new Error("COMFYUI_ENDPOINT_URL is not set.");

  const supabase = createClient(SUPABASE_URL!, SUPABASE_SERVICE_ROLE_KEY!);
  const sanitizedAddress = COMFYUI_ENDPOINT_URL.replace(/\/+$/, "");

  try {
    const { base_model_url, pose_prompt, pose_image_url } = await req.json();
    if (!base_model_url || !pose_prompt) {
      throw new Error("base_model_url and pose_prompt are required.");
    }

    console.log(`[PoseGenerator][${requestId}] Downloading base model from: ${base_model_url}`);
    const baseModelBlob = await downloadFromSupabase(supabase, base_model_url);
    const baseModelFilename = await uploadToComfyUI(sanitizedAddress, baseModelBlob, 'base_model.png');
    console.log(`[PoseGenerator][${requestId}] Base model uploaded to ComfyUI as: ${baseModelFilename}`);

    const workflow = pose_image_url ? workflowWithRef : workflowWithoutRef;
    const finalWorkflow = JSON.parse(JSON.stringify(workflow));

    finalWorkflow['214'].inputs.image = baseModelFilename;
    finalWorkflow['193'].inputs.String = pose_prompt;

    if (pose_image_url) {
      console.log(`[PoseGenerator][${requestId}] Downloading pose reference from: ${pose_image_url}`);
      const poseImageBlob = await downloadFromSupabase(supabase, pose_image_url);
      const poseImageFilename = await uploadToComfyUI(sanitizedAddress, poseImageBlob, 'pose_ref.png');
      finalWorkflow['215'].inputs.image = poseImageFilename;
      console.log(`[PoseGenerator][${requestId}] Pose reference uploaded as: ${poseImageFilename}`);
    }

    const queueUrl = `${sanitizedAddress}/prompt`;
    const response = await fetch(queueUrl, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt: finalWorkflow })
    });
    if (!response.ok) throw new Error(`ComfyUI server error: ${await response.text()}`);
    
    const data = await response.json();
    if (!data.prompt_id) throw new Error("ComfyUI did not return a prompt_id.");
    console.log(`[PoseGenerator][${requestId}] Job queued successfully with prompt_id: ${data.prompt_id}`);

    return new Response(JSON.stringify({ comfyui_prompt_id: data.prompt_id }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 200,
    });

  } catch (error) {
    console.error(`[PoseGenerator][${requestId}] Error:`, error);
    return new Response(JSON.stringify({ error: error.message }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 500,
    });
  }
});